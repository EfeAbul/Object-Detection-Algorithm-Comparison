{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN6QX3cKuS7H"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision pycocotools opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_name = \"/content/My First Project.v1i.coco.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset\")\n"
      ],
      "metadata": {
        "id": "P3KHhSWhzp1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.transforms import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "rMV3v8hwBgKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.transforms import functional as F\n",
        "import torchvision.ops as ops\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# === Dataset Transform ===\n",
        "class CocoTransform:\n",
        "    def __call__(self, image, target):\n",
        "        return F.to_tensor(image), target\n",
        "\n",
        "# === Dataset Yükleyici ===\n",
        "def get_coco_dataset(img_dir, ann_file):\n",
        "    return CocoDetection(\n",
        "        root=img_dir,\n",
        "        annFile=ann_file,\n",
        "        transforms=CocoTransform()\n",
        "    )\n",
        "\n",
        "train_dataset = get_coco_dataset(\"/content/dataset/train\", \"/content/dataset/train/_annotations.coco.json\")\n",
        "val_dataset = get_coco_dataset(\"/content/dataset/valid\", \"/content/dataset/valid/_annotations.coco.json\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "# === Model Tanımı ===\n",
        "def get_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "num_classes = 6  # background + 5 sınıf\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = get_model(num_classes)\n",
        "model.to(device)\n",
        "\n",
        "# === Optimizer ve Scheduler ===\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "# === Log listeleri ===\n",
        "train_losses = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "val_map50 = []\n",
        "val_map5095 = []\n",
        "\n",
        "# === Eğitim Fonksiyonu ===\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, targets in data_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        processed_targets = []\n",
        "        valid_images = []\n",
        "\n",
        "        for i, target in enumerate(targets):\n",
        "            boxes = []\n",
        "            labels = []\n",
        "            for obj in target:\n",
        "                x, y, w, h = obj[\"bbox\"]\n",
        "                if w > 0 and h > 0:\n",
        "                    boxes.append([x, y, x + w, y + h])\n",
        "                    labels.append(obj[\"category_id\"])\n",
        "            if boxes:\n",
        "                processed_target = {\n",
        "                    \"boxes\": torch.tensor(boxes, dtype=torch.float32).to(device),\n",
        "                    \"labels\": torch.tensor(labels, dtype=torch.int64).to(device),\n",
        "                }\n",
        "                processed_targets.append(processed_target)\n",
        "                valid_images.append(images[i])\n",
        "\n",
        "        if not processed_targets:\n",
        "            continue\n",
        "\n",
        "        images = valid_images\n",
        "        loss_dict = model(images, processed_targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += losses.item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "    print(f\"[Epoch {epoch}] Avg Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# === Değerlendirme Fonksiyonu ===\n",
        "def evaluate_model(model, data_loader, device, iou_threshold=0.5, score_threshold=0.5):\n",
        "    model.eval()\n",
        "    total_tp = defaultdict(int)\n",
        "    total_fp = defaultdict(int)\n",
        "    total_fn = defaultdict(int)\n",
        "    ap_per_class = defaultdict(list)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = [img.to(device) for img in images]\n",
        "            outputs = model(images)\n",
        "\n",
        "            for output, target in zip(outputs, targets):\n",
        "                if len(target) == 0:\n",
        "                    continue\n",
        "\n",
        "                pred_boxes = output['boxes']\n",
        "                pred_labels = output['labels']\n",
        "                pred_scores = output['scores']\n",
        "\n",
        "                gt_boxes = torch.tensor([obj[\"bbox\"] for obj in target], dtype=torch.float32).to(device)\n",
        "                if gt_boxes.ndim == 1:\n",
        "                    gt_boxes = gt_boxes.unsqueeze(0)\n",
        "                gt_boxes[:, 2] += gt_boxes[:, 0]\n",
        "                gt_boxes[:, 3] += gt_boxes[:, 1]\n",
        "                gt_labels = torch.tensor([obj[\"category_id\"] for obj in target]).to(device)\n",
        "\n",
        "                keep = pred_scores > score_threshold\n",
        "                pred_boxes = pred_boxes[keep]\n",
        "                pred_labels = pred_labels[keep]\n",
        "\n",
        "                matched_gt = set()\n",
        "                for i in range(len(pred_boxes)):\n",
        "                    box = pred_boxes[i].unsqueeze(0)\n",
        "                    label = pred_labels[i].item()\n",
        "                    ious = ops.box_iou(box, gt_boxes)\n",
        "                    iou_max, idx = ious.max(1)\n",
        "                    idx = idx.item()\n",
        "\n",
        "                    if iou_max.item() >= iou_threshold and gt_labels[idx].item() == label and idx not in matched_gt:\n",
        "                        total_tp[label] += 1\n",
        "                        matched_gt.add(idx)\n",
        "                        ap_per_class[label].append(iou_max.item())\n",
        "                    else:\n",
        "                        total_fp[label] += 1\n",
        "\n",
        "                for i, lbl in enumerate(gt_labels):\n",
        "                    if i not in matched_gt:\n",
        "                        total_fn[lbl.item()] += 1\n",
        "\n",
        "    total_p, total_r, total_ap50, total_ap5095, count = 0, 0, 0, 0, 0\n",
        "\n",
        "    for label in total_tp:\n",
        "        tp = total_tp[label]\n",
        "        fp = total_fp[label]\n",
        "        fn = total_fn[label]\n",
        "        p = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        r = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        aps = ap_per_class[label]\n",
        "        ap50 = sum([1 if ap > 0.5 else 0 for ap in aps]) / len(aps) if aps else 0\n",
        "        ap5095 = sum(aps) / len(aps) if aps else 0\n",
        "        total_p += p\n",
        "        total_r += r\n",
        "        total_ap50 += ap50\n",
        "        total_ap5095 += ap5095\n",
        "        count += 1\n",
        "\n",
        "    avg_p = total_p / count\n",
        "    avg_r = total_r / count\n",
        "    avg_ap50 = total_ap50 / count\n",
        "    avg_ap5095 = total_ap5095 / count\n",
        "\n",
        "    val_precisions.append(avg_p)\n",
        "    val_recalls.append(avg_r)\n",
        "    val_map50.append(avg_ap50)\n",
        "    val_map5095.append(avg_ap5095)\n",
        "\n",
        "    print(f\"Precision: {avg_p:.3f}, Recall: {avg_r:.3f}, mAP50: {avg_ap50:.3f}, mAP50-95: {avg_ap5095:.3f}\")\n",
        "\n",
        "# === Eğitim Döngüsü ===\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "    lr_scheduler.step()\n",
        "    evaluate_model(model, val_loader, device)\n",
        "    torch.save(model.state_dict(), f\"fasterrcnn_epoch_{epoch+1}.pth\")\n",
        "\n",
        "# === Grafik Çizimi ===\n",
        "metrics = [\n",
        "    train_losses, val_precisions, val_recalls,\n",
        "    val_map50, val_map5095\n",
        "]\n",
        "\n",
        "titles = [\n",
        "    \"train/loss\", \"val/precision\", \"val/recall\",\n",
        "    \"metrics/mAP50\", \"metrics/mAP50-95\"\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "for i, data in enumerate(metrics):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.plot(data, label='value', marker='o')\n",
        "    if len(data) >= 5:\n",
        "        plt.plot(pd.Series(data).rolling(3).mean(), linestyle='dotted', label='smooth')\n",
        "    plt.title(titles[i])\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1MH3kTIiBkI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "def get_coco_dataset(img_dir, ann_file):\n",
        "    return CocoDetection(\n",
        "        root=img_dir,\n",
        "        annFile=ann_file,\n",
        "        transforms=CocoTransform()\n",
        "    )\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = get_coco_dataset(\n",
        "    img_dir=\"/content/dataset/train\",\n",
        "    ann_file=\"/content/dataset/train/_annotations.coco.json\"\n",
        ")\n",
        "\n",
        "\n",
        "val_dataset = get_coco_dataset(\n",
        "    img_dir=\"/content/dataset/valid\",\n",
        "    ann_file=\"/content/dataset/valid/_annotations.coco.json\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
      ],
      "metadata": {
        "id": "X7UdafEpB6Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Faster R-CNN with ResNet-50 backbone\n",
        "def get_model(num_classes):\n",
        "    # Load pre-trained Faster R-CNN\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # Get the number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "    # Replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "7fZ5x7DZC1Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "num_classes = 6 # Background + car, bus, truck, motorcycle, ambulance\n",
        "model = get_model(num_classes)"
      ],
      "metadata": {
        "id": "XYx9IudPC2Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Sınıf isimleri\n",
        "COCO_CLASSES = {\n",
        "    0: \"Background\",\n",
        "    1: \"ambulance\",\n",
        "    2: \"bus\",\n",
        "    3: \"car\",\n",
        "    4: \"motorcycle\",\n",
        "    5: \"truck\"\n",
        "}\n",
        "\n",
        "def get_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "num_classes = 6\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Modeli yükle\n",
        "model = get_model(num_classes)\n",
        "model.load_state_dict(torch.load(\"/content/fasterrcnn_epoch_10.pth\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Görseli hazırla\n",
        "def prepare_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_tensor = F.to_tensor(image).unsqueeze(0)\n",
        "    return image_tensor.to(device)\n",
        "\n",
        "# Sınıf adını getir\n",
        "def get_class_name(class_id):\n",
        "    return COCO_CLASSES.get(class_id, \"Unknown\")\n",
        "\n",
        "# Kutuları çiz\n",
        "def draw_boxes(image, prediction, fig_size=(12, 10), threshold=0.5):\n",
        "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "    labels = prediction[0]['labels'].cpu().numpy()\n",
        "    scores = prediction[0]['scores'].cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=fig_size)\n",
        "    plt.imshow(image)\n",
        "\n",
        "    ax = plt.gca()\n",
        "\n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        if score > threshold:\n",
        "            x_min, y_min, x_max, y_max = box\n",
        "            class_name = get_class_name(label)\n",
        "            rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,\n",
        "                                 linewidth=2, edgecolor='r', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "            ax.text(x_min, y_min - 5, f\"{class_name} ({score:.2f})\", color='red', fontsize=12,\n",
        "                    backgroundcolor=\"white\")\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Tahmin yap ve çiz\n",
        "image_path = \"/content/dataset/valid/f971dfb20ee52e9b_jpg.rf.a6484c46c580abcacfd67eb69078cbf8.jpg\"\n",
        "image_tensor = prepare_image(image_path)\n",
        "\n",
        "image_path1 = \"/content/dataset/valid/a427d2734cc7e939_jpg.rf.72b37ad5c1e030b6299ad61ae02da238.jpg\"\n",
        "image_tensor1 = prepare_image(image_path1)\n",
        "\n",
        "image_path2 = \"/content/dataset/valid/9d2d424099458956_jpg.rf.3e56b70f5e4fcc506d9221ee136625ea.jpg\"\n",
        "image_tensor2 = prepare_image(image_path2)\n",
        "\n",
        "image_path3 = \"/content/dataset/valid/f0f3c1c5237b0b1e_jpg.rf.3f6743c8d1005818afa2c089492569e6.jpg\"\n",
        "image_tensor3 = prepare_image(image_path3)\n",
        "\n",
        "image_path4 = \"/content/dataset/valid/fb70621f1a194c73_jpg.rf.e8a16c23912a8a5db5e16c78b70c5491.jpg\"\n",
        "image_tensor4 = prepare_image(image_path4)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = model(image_tensor)\n",
        "\n",
        "draw_boxes(Image.open(image_path), prediction)\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction1 = model(image_tensor1)\n",
        "\n",
        "draw_boxes(Image.open(image_path1), prediction1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction2 = model(image_tensor2)\n",
        "\n",
        "draw_boxes(Image.open(image_path2), prediction2)\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction3 = model(image_tensor3)\n",
        "\n",
        "draw_boxes(Image.open(image_path3), prediction3)\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction4 = model(image_tensor4)\n",
        "\n",
        "draw_boxes(Image.open(image_path4), prediction4)\n"
      ],
      "metadata": {
        "id": "t-dKUH4dQ2Zt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}